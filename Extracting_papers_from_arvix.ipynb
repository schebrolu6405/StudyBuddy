{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install arxiv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWemL92rnfXa",
        "outputId": "7926f862-7803-4473-b22c-343a2f1747ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting feedparser~=6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.11/dist-packages (from arxiv) (2.32.3)\n",
            "Collecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.32.0->arxiv) (2025.1.31)\n",
            "Downloading arxiv-2.1.3-py3-none-any.whl (11 kB)\n",
            "Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6047 sha256=59d5ccc017d73868303bfaeaa5312df1a18685d6485cd526fe6c7e866605d20d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/25/2a/105d6a15df6914f4d15047691c6c28f9052cc1173e40285d03\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
            "Successfully installed arxiv-2.1.3 feedparser-6.0.11 sgmllib3k-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import arxiv\n",
        "import openai\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "_dB2YX2YnCpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone"
      ],
      "metadata": {
        "id": "nAb0Szajp1p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_arxiv(query,max_results = 3):\n",
        "  client = arxiv.Client(page_size = max_results,delay_seconds = 3)\n",
        "  search = arxiv.Search(query = query,max_results = max_results,sort_by=arxiv.SortCriterion.Relevance, sort_order=arxiv.SortOrder.Descending)\n",
        "  results = []\n",
        "  for result in client.results(search):\n",
        "    paper = {\n",
        "         \"title\": result.title,\n",
        "         \"summary\": result.summary,\n",
        "         \"authors\": \", \".join([author.name for author in result.authors]),\n",
        "         \"published\": result.published,\n",
        "         \"pdf_url\": result.pdf_url,\n",
        "         \"primary_category\" : result.primary_category,\n",
        "          \"arxiv_id\": result.entry_id.split(\"/\")[-1]  # Extracts the arXiv ID\n",
        "    }\n",
        "    results.append(paper)\n",
        "\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "GvQGY9sRn1kG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_citation_count(arxiv_id):\n",
        "    \"\"\"Scrape Google Scholar to get citation count for a given arXiv paper.\"\"\"\n",
        "    search_url = f\"https://scholar.google.com/scholar?q={arxiv_id}\"\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "    response = requests.get(search_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        citation_div = soup.find(\"a\", string=lambda text: text and \"Cited by\" in text)\n",
        "        if citation_div:\n",
        "            return int(citation_div.text.split(\"by\")[-1].strip())\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "WjhQgXMEt06T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    #query = \"large language models in NLP\"\n",
        "    query = \"non linear interference modelling for full duplex using memory polynomials\"\n",
        "    papers = search_arxiv(query)\n"
      ],
      "metadata": {
        "id": "w6e2OAM3pThJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for i, paper in enumerate(papers):\n",
        "        print(f\"\\nPaper {i+1}: {paper['title']}\")\n",
        "        print(f\"Primary category: {paper['primary_category']}\")\n",
        "\n",
        "        citation_count = get_citation_count(paper['arxiv_id'])\n",
        "        print(f\"Citations: {citation_count}\")\n",
        "\n",
        "        print(f\"Authors: {paper['authors']}\")\n",
        "        print(f\"Published: {paper['published']}\")\n",
        "        print(f\"PDF: {paper['pdf_url']}\")\n",
        "        print(f\"Summary: {paper['summary']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj31BrWzpdjC",
        "outputId": "35ef41e4-68fa-4741-d022-6b75cb38657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Paper 1: Non-Linear Self-Interference Cancellation via Tensor Completion\n",
            "Primary category: eess.SP\n",
            "Citations: 0\n",
            "Authors: Freek Jochems, Alexios Balatsoukas-Stimming\n",
            "Published: 2020-10-05 09:08:28+00:00\n",
            "PDF: http://arxiv.org/pdf/2010.01868v1\n",
            "Summary: Non-linear self-interference (SI) cancellation constitutes a fundamental\n",
            "problem in full-duplex communications, which is typically tackled using either\n",
            "polynomial models or neural networks. In this work, we explore the\n",
            "applicability of a recently proposed method based on low-rank tensor\n",
            "completion, called canonical system identification (CSID), to non-linear SI\n",
            "cancellation. Our results show that CSID is very effective in modeling and\n",
            "cancelling the non-linear SI signal and can have lower computational complexity\n",
            "than existing methods, albeit at the cost of increased memory requirements.\n",
            "\n",
            "Paper 2: Design and Implementation of a Neural Network Aided Self-Interference Cancellation Scheme for Full-Duplex Radios\n",
            "Primary category: eess.SP\n",
            "Citations: 0\n",
            "Authors: Yann Kurzo, Andreas Burg, Alexios Balatsoukas-Stimming\n",
            "Published: 2018-12-02 19:16:30+00:00\n",
            "PDF: http://arxiv.org/pdf/1812.00449v1\n",
            "Summary: In-band full-duplex systems are able to transmit and receive information\n",
            "simultaneously on the same frequency band. Due to the strong self-interference\n",
            "caused by the transmitter to its own receiver, the use of non-linear digital\n",
            "self-interference cancellation is essential. In this work, we present a\n",
            "hardware architecture for a neural network based non-linear self-interference\n",
            "canceller and we compare it with our own hardware implementation of a\n",
            "conventional polynomial based canceller. We show that, for the same\n",
            "cancellation performance, the neural network canceller has a significantly\n",
            "higher throughput and requires fewer hardware resources.\n",
            "\n",
            "Paper 3: Non-Linear Digital Self-Interference Cancellation for In-Band Full-Duplex Radios Using Neural Networks\n",
            "Primary category: eess.SP\n",
            "Citations: 0\n",
            "Authors: Alexios Balatsoukas-Stimming\n",
            "Published: 2017-11-01 14:46:13+00:00\n",
            "PDF: http://arxiv.org/pdf/1711.00379v4\n",
            "Summary: Full-duplex systems require very strong self-interference cancellation in\n",
            "order to operate correctly and a significant part of the self-interference\n",
            "signal is due to non-linear effects created by various transceiver impairments.\n",
            "As such, linear cancellation alone is usually not sufficient and sophisticated\n",
            "non-linear cancellation algorithms have been proposed in the literature. In\n",
            "this work, we investigate the use of a neural network as an alternative to the\n",
            "traditional non-linear cancellation method that is based on polynomial basis\n",
            "functions. Measurement results from a full-duplex testbed demonstrate that a\n",
            "small and simple feed-forward neural network canceler works exceptionally well,\n",
            "as it can match the performance of the polynomial non-linear canceler with\n",
            "significantly lower computational complexity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51YAbBo3pmDr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}