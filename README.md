## ğŸ“š StudyBuddy â€“ Multimodal AI Research Assistant

### ğŸ” Problem Statement

Navigating the immense volume of scientific papers has become a growing challenge for students and researchers. These documents often contain complex visual elements like plots, diagrams, and tables that require careful interpretation along with dense textual explanations. Manual reading is time-consuming, inefficient, and limits effective knowledge extraction.

### ğŸ¯ Project Objective

**StudyBuddy** is designed to simplify and accelerate the academic research process by using **multimodal Retrieval-Augmented Generation (RAG)** with **large language models (LLMs)**. It processes scientific PDFs from ArXiv and allows users to interactively query the paper, receiving grounded, context-aware answers based on both textual and visual elements.

---

### âš™ï¸ Key Features

- **Automated Document Parsing**  
  Extracts structured elements from scientific PDFs including text, tables, figures, and formulas using `Unstructured` and `PyMuPDF`.

- **Multimodal Summarization**  
  Summarizes extracted content using **GPT-4o** and **Gemini 2.0 Flash**, enabling rich responses that integrate image and table data.

- **Context-Grounded Q&A**  
  Users can ask natural language questions about the paper and get AI-generated responses based on the content (not external data).

- **Vector Database Integration**  
  Uses **ChromaDB** and **Qdrant** to store and retrieve high-dimensional embeddings of text and image content for semantically rich responses.

- **Streamlit Interface**  
  A user-friendly front-end built with Streamlit, deployed on Hugging Face Spaces for zero-setup usage.

---

### ğŸ§  Model Architecture

- **LLMs Used**:  
  - GPT-4o (OpenAI) â€“ For native multimodal understanding  
  - Gemini 2.0 Flash (Google) â€“ For cost-efficient image + text responses

- **Pipeline**:  
  1. Retrieve relevant PDFs from ArXiv  
  2. Parse and chunk into images, tables, text  
  3. Store embeddings in vector DB  
  4. On query, fetch relevant content  
  5. Generate structured answer via LLM

---

### ğŸŒ Resources

- ğŸ“„ [Project Report (PDF)](https://docs.google.com/document/d/1_4LfmFB85sGBVFCVP_1cCqba1IYvdhb2I4vMa9eugHw/edit?usp=sharing)  
- ğŸŒ [Website](https://dipsydhanda.wixsite.com/studdy-buddy)  
- ğŸ“½ï¸ [Demo Video](https://youtu.be/wF4oBphiWvE)  
- ğŸ“Š [Presentation](https://docs.google.com/presentation/d/1koWmY0ey6sUFsV9JUEnUeBpvmLZ71exClh6TueN5gKc)  
- ğŸ“š [arXiv](https://arxiv.org/)

---

### ğŸ‘¥ Contributors


- **Anurima Saha** â€“ GPT-4 RAG, Evaluation, Presentation
- **Susheel Chebrolu** â€“ Data collection (ArXiv), Gemini-based RAG, Report  
- **Dipsy** â€“ Streamlit Integration, Website, Application UI

---

